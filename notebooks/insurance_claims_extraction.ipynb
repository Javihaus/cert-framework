{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Insurance Claims Document Extraction with CERT Monitoring\n",
        "\n",
        "A **production-grade document extraction pipeline** for processing insurance claims documents using Claude Sonnet 4.5, with hallucination detection via CERT Grounding Check.\n",
        "\n",
        "## Real-World Use Case\n",
        "\n",
        "Insurance companies process thousands of claims daily, each requiring:\n",
        "- Extraction of key policy information\n",
        "- Incident details and timeline reconstruction\n",
        "- Damage assessment and cost estimates\n",
        "- Fraud indicator detection\n",
        "- Coverage verification against policy terms\n",
        "\n",
        "**Critical Requirement**: Extracted information MUST be verifiable against source documents. Hallucinated data in insurance claims can lead to:\n",
        "- Incorrect payouts (financial loss)\n",
        "- Denied legitimate claims (customer harm)\n",
        "- Regulatory violations (legal liability)\n",
        "- Fraud exposure (security risk)\n",
        "\n",
        "## Architecture\n",
        "\n",
        "```\n",
        "Insurance Claim Documents (PDF/Images)\n",
        "              │\n",
        "              ▼\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│  Document Preprocessor                                      │\n",
        "│  → Text extraction, OCR if needed, chunk splitting         │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "              │\n",
        "              ▼\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│  Claude Sonnet 4.5 - Structured Extraction                  │\n",
        "│  → Policy details, claimant info, incident data            │\n",
        "│  → Source chunks sent as context                           │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "              │\n",
        "              ▼\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│  Claude Sonnet 4.5 - Risk Assessment                        │\n",
        "│  → Fraud indicators, coverage gaps, liability analysis     │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "              │\n",
        "              ▼\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│  CERT Dashboard                                             │\n",
        "│  • Grounding Check: Verify all extracted data exists in    │\n",
        "│    source documents (hallucination detection)              │\n",
        "│  • Quality metrics: Extraction accuracy over time          │\n",
        "│  • Cost tracking: Per-claim processing costs               │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "## Why Claude Sonnet 4.5?\n",
        "\n",
        "- **Long Context**: 200K tokens handles multi-page policy documents\n",
        "- **Structured Output**: Excellent at following JSON schemas\n",
        "- **Reasoning**: Can identify inconsistencies and fraud indicators\n",
        "- **Accuracy**: Lower hallucination rate than alternatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q anthropic pydantic requests\n",
        "\n",
        "print(\"Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# =============================================================\n",
        "# API KEYS CONFIGURATION\n",
        "# =============================================================\n",
        "\n",
        "CERT_DASHBOARD_URL = \"https://dashboard.cert-framework.com\"\n",
        "\n",
        "if 'CERT_API_KEY' not in os.environ:\n",
        "    os.environ['CERT_API_KEY'] = getpass('Enter your CERT API Key: ')\n",
        "\n",
        "if 'ANTHROPIC_API_KEY' not in os.environ:\n",
        "    os.environ['ANTHROPIC_API_KEY'] = getpass('Enter your Anthropic API key: ')\n",
        "\n",
        "CERT_API_KEY = os.environ['CERT_API_KEY']\n",
        "ANTHROPIC_API_KEY = os.environ['ANTHROPIC_API_KEY']\n",
        "\n",
        "print(f\"CERT Dashboard: {CERT_DASHBOARD_URL}\")\n",
        "print(f\"CERT API Key: {CERT_API_KEY[:20]}...\")\n",
        "print(f\"Anthropic API Key: {ANTHROPIC_API_KEY[:20]}... (stays local)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. CERT Tracer with Grounding Check Support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import List, Optional, Dict, Any\n",
        "\n",
        "class CERTTracer:\n",
        "    \"\"\"\n",
        "    CERT Dashboard Tracer with Grounding Check support.\n",
        "    \n",
        "    For document extraction, we send source chunks as 'context'\n",
        "    to enable Grounding Check evaluation - verifying that extracted\n",
        "    information actually exists in the source documents.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dashboard_url: str, api_key: str, project_name: str = \"default\"):\n",
        "        self.endpoint = f\"{dashboard_url.rstrip('/')}/api/v1/traces\"\n",
        "        self.api_key = api_key\n",
        "        self.project_name = project_name\n",
        "        self.session_id = str(uuid.uuid4())[:8]\n",
        "        self.traces_sent = 0\n",
        "        self.total_tokens = 0\n",
        "        \n",
        "    def _get_headers(self) -> Dict[str, str]:\n",
        "        return {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"X-API-Key\": self.api_key\n",
        "        }\n",
        "    \n",
        "    def send_trace(self, trace_data: dict) -> bool:\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                self.endpoint,\n",
        "                json={\"traces\": [trace_data]},\n",
        "                headers=self._get_headers(),\n",
        "                timeout=15\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                self.traces_sent += 1\n",
        "                result = response.json()\n",
        "                storage = \"database\" if result.get('stored_in_db') else \"memory\"\n",
        "                print(f\"  [CERT] Trace sent -> stored in {storage}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"  [CERT] Error {response.status_code}: {response.text[:100]}\")\n",
        "                return False\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  [CERT] Connection error: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def trace_extraction(\n",
        "        self,\n",
        "        model: str,\n",
        "        input_text: str,\n",
        "        output_text: str,\n",
        "        duration_ms: float,\n",
        "        prompt_tokens: int,\n",
        "        completion_tokens: int,\n",
        "        source_chunks: List[str],\n",
        "        extraction_type: str,\n",
        "        document_id: str = None,\n",
        "        metadata: Optional[Dict[str, Any]] = None\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Record a document extraction trace with source context.\n",
        "        \n",
        "        The source_chunks parameter is critical - it enables CERT's\n",
        "        Grounding Check to verify extracted data exists in sources.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.total_tokens += prompt_tokens + completion_tokens\n",
        "        \n",
        "        trace = {\n",
        "            \"id\": f\"{self.session_id}-{str(uuid.uuid4())[:8]}\",\n",
        "            \"provider\": \"anthropic\",\n",
        "            \"model\": model,\n",
        "            \"input\": input_text[:1000] + \"...\" if len(input_text) > 1000 else input_text,\n",
        "            \"output\": output_text,\n",
        "            \"promptTokens\": prompt_tokens,\n",
        "            \"completionTokens\": completion_tokens,\n",
        "            \"durationMs\": round(duration_ms, 2),\n",
        "            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "            \"context\": source_chunks,  # Critical for Grounding Check!\n",
        "            \"metadata\": {\n",
        "                \"project\": self.project_name,\n",
        "                \"session_id\": self.session_id,\n",
        "                \"extraction_type\": extraction_type,\n",
        "                \"document_id\": document_id,\n",
        "                \"source_chunk_count\": len(source_chunks),\n",
        "                **(metadata or {})\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        self.send_trace(trace)\n",
        "        return trace\n",
        "\n",
        "# Initialize tracer\n",
        "tracer = CERTTracer(\n",
        "    dashboard_url=CERT_DASHBOARD_URL,\n",
        "    api_key=CERT_API_KEY,\n",
        "    project_name=\"insurance-claims-extraction\"\n",
        ")\n",
        "\n",
        "print(f\"CERT Tracer initialized\")\n",
        "print(f\"  Session: {tracer.session_id}\")\n",
        "print(f\"  Grounding Check: ENABLED (source context will be sent)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Sample Insurance Claim Documents\n",
        "\n",
        "In production, these would be parsed from PDFs. For this demo, we use realistic document text that mimics actual insurance claims."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# SAMPLE INSURANCE CLAIM DOCUMENTS\n",
        "# =============================================================\n",
        "\n",
        "CLAIM_DOCUMENTS = {\n",
        "    \"CLM-2024-78432\": {\n",
        "        \"type\": \"auto_collision\",\n",
        "        \"policy_document\": \"\"\"\n",
        "LIBERTY MUTUAL INSURANCE COMPANY\n",
        "AUTO INSURANCE POLICY\n",
        "\n",
        "Policy Number: AUT-7834521-2024\n",
        "Effective Date: January 1, 2024\n",
        "Expiration Date: January 1, 2025\n",
        "\n",
        "NAMED INSURED:\n",
        "Name: Jennifer Marie Thompson\n",
        "Address: 4521 Oak Valley Drive, Austin, TX 78749\n",
        "Date of Birth: March 15, 1985\n",
        "Driver's License: TX-12345678\n",
        "\n",
        "COVERED VEHICLE:\n",
        "Year: 2022\n",
        "Make: Toyota\n",
        "Model: Camry XSE\n",
        "VIN: 4T1BZ1HK3NU123456\n",
        "License Plate: ABC-1234 (Texas)\n",
        "\n",
        "COVERAGE DETAILS:\n",
        "Liability - Bodily Injury: $100,000 per person / $300,000 per accident\n",
        "Liability - Property Damage: $100,000 per accident\n",
        "Collision: $500 deductible\n",
        "Comprehensive: $250 deductible\n",
        "Medical Payments: $10,000 per person\n",
        "Uninsured Motorist: $100,000/$300,000\n",
        "\n",
        "PREMIUM:\n",
        "Annual Premium: $1,847.00\n",
        "Payment Status: PAID IN FULL\n",
        "\n",
        "ADDITIONAL DRIVERS:\n",
        "1. Michael Thompson (Spouse) - DOB: June 22, 1983\n",
        "2. Emma Thompson (Child) - DOB: September 8, 2005 - Restricted license\n",
        "\"\"\",\n",
        "        \"claim_form\": \"\"\"\n",
        "FIRST NOTICE OF LOSS - AUTO CLAIM\n",
        "\n",
        "Claim Number: CLM-2024-78432\n",
        "Date of Loss: November 15, 2024\n",
        "Time of Loss: 8:45 AM\n",
        "Date Reported: November 15, 2024\n",
        "\n",
        "INCIDENT LOCATION:\n",
        "Address: Intersection of Congress Avenue and 6th Street\n",
        "City: Austin\n",
        "State: Texas\n",
        "ZIP: 78701\n",
        "\n",
        "INCIDENT DESCRIPTION:\n",
        "Claimant was traveling northbound on Congress Avenue at approximately 25 mph.\n",
        "At the intersection with 6th Street, a white Ford F-150 pickup truck ran the\n",
        "red light traveling eastbound and struck the claimant's vehicle on the driver's\n",
        "side rear quarter panel. The impact caused the claimant's vehicle to spin and\n",
        "collide with a light pole on the northwest corner of the intersection.\n",
        "\n",
        "WEATHER CONDITIONS: Clear, dry pavement\n",
        "ROAD CONDITIONS: Urban intersection, traffic signals present\n",
        "VISIBILITY: Good (daylight)\n",
        "\n",
        "INJURIES CLAIMED:\n",
        "- Jennifer Thompson: Whiplash, left shoulder strain. Transported to \n",
        "  St. David's Medical Center by EMS. Released same day.\n",
        "- No other occupants in claimant vehicle.\n",
        "\n",
        "OTHER PARTY INFORMATION:\n",
        "Driver: Robert James Miller\n",
        "Address: 892 Lamar Boulevard, Austin, TX 78703\n",
        "Phone: (512) 555-0147\n",
        "Insurance: State Farm, Policy #: SF-9876543\n",
        "Vehicle: 2021 Ford F-150 (White)\n",
        "License Plate: XYZ-9876 (Texas)\n",
        "\n",
        "POLICE REPORT:\n",
        "Report Filed: Yes\n",
        "Report Number: APD-2024-1115-0847\n",
        "Responding Officer: Officer Maria Santos, Badge #4521\n",
        "Citations Issued: Robert Miller cited for running red light (TX Trans Code 544.007)\n",
        "\n",
        "WITNESSES:\n",
        "1. David Chen, (512) 555-0234 - Was in vehicle behind claimant\n",
        "2. Sarah Williams, (512) 555-0891 - Pedestrian on corner\n",
        "\"\"\",\n",
        "        \"damage_estimate\": \"\"\"\n",
        "COLLISION REPAIR ESTIMATE\n",
        "Austin Auto Body & Paint\n",
        "Estimate Date: November 18, 2024\n",
        "\n",
        "Vehicle: 2022 Toyota Camry XSE\n",
        "VIN: 4T1BZ1HK3NU123456\n",
        "Mileage: 34,521\n",
        "\n",
        "DAMAGE ASSESSMENT:\n",
        "\n",
        "LEFT SIDE DAMAGE:\n",
        "- Left rear quarter panel: REPLACE - $1,847.00\n",
        "- Left rear door: REPAIR/REFINISH - $890.00\n",
        "- Left tail light assembly: REPLACE - $425.00\n",
        "- Left rear wheel: REPLACE - $387.00\n",
        "- Left rear tire: REPLACE - $189.00\n",
        "\n",
        "REAR DAMAGE:\n",
        "- Rear bumper cover: REPLACE - $567.00\n",
        "- Rear bumper reinforcement: REPLACE - $234.00\n",
        "- Trunk lid: REPAIR/REFINISH - $445.00\n",
        "\n",
        "FRONT DAMAGE (from light pole impact):\n",
        "- Front bumper cover: REPLACE - $623.00\n",
        "- Hood: REPAIR - $567.00\n",
        "- Right headlight assembly: REPLACE - $892.00\n",
        "- Radiator support: REPAIR - $445.00\n",
        "\n",
        "MECHANICAL:\n",
        "- Wheel alignment: $129.00\n",
        "- Suspension inspection: $89.00\n",
        "- A/C recharge (system opened): $175.00\n",
        "\n",
        "PAINT AND MATERIALS:\n",
        "- Paint labor: $1,200.00\n",
        "- Paint materials: $567.00\n",
        "- Body filler materials: $123.00\n",
        "\n",
        "LABOR:\n",
        "- Body labor (32 hours @ $65/hr): $2,080.00\n",
        "- Mechanical labor (4 hours @ $95/hr): $380.00\n",
        "- Frame labor (6 hours @ $85/hr): $510.00\n",
        "\n",
        "SUBTOTAL: $12,764.00\n",
        "TAX (8.25%): $1,053.03\n",
        "\n",
        "TOTAL ESTIMATE: $13,817.03\n",
        "\n",
        "VEHICLE VALUE ASSESSMENT:\n",
        "Pre-accident fair market value: $28,500.00\n",
        "Recommendation: REPAIR (estimate < 60% of value)\n",
        "\n",
        "Estimator: Carlos Rodriguez\n",
        "License #: TX-EST-45678\n",
        "\"\"\",\n",
        "        \"medical_records\": \"\"\"\n",
        "ST. DAVID'S MEDICAL CENTER\n",
        "EMERGENCY DEPARTMENT RECORDS\n",
        "\n",
        "Patient: Jennifer Marie Thompson\n",
        "DOB: 03/15/1985\n",
        "MRN: SDM-7823456\n",
        "Date of Service: November 15, 2024\n",
        "Time of Arrival: 9:23 AM\n",
        "Time of Discharge: 1:45 PM\n",
        "\n",
        "CHIEF COMPLAINT: \n",
        "38-year-old female presents following motor vehicle collision. \n",
        "Patient was driver of vehicle struck by another car running red light.\n",
        "Complains of neck pain, left shoulder pain, and headache.\n",
        "\n",
        "VITAL SIGNS ON ARRIVAL:\n",
        "BP: 142/88 (elevated, likely due to stress)\n",
        "HR: 94\n",
        "RR: 18\n",
        "Temp: 98.4F\n",
        "O2 Sat: 99% on room air\n",
        "\n",
        "PHYSICAL EXAMINATION:\n",
        "General: Alert, oriented x4, in mild distress due to pain\n",
        "HEENT: No facial lacerations, pupils equal and reactive\n",
        "Neck: Tenderness to palpation at C5-C6, limited ROM due to pain\n",
        "         No step-off, no crepitus\n",
        "Chest: Clear to auscultation bilaterally\n",
        "Left Shoulder: Tenderness over deltoid, limited abduction to 90 degrees\n",
        "                No deformity, neurovascular intact distally\n",
        "\n",
        "IMAGING:\n",
        "C-Spine X-ray (3 views): No acute fracture or dislocation. \n",
        "                         Mild straightening of cervical lordosis.\n",
        "Left Shoulder X-ray (2 views): No fracture. No dislocation.\n",
        "CT Head (non-contrast): No acute intracranial abnormality.\n",
        "\n",
        "DIAGNOSIS:\n",
        "1. Cervical strain (whiplash) - ICD-10: S13.4XXA\n",
        "2. Left shoulder strain - ICD-10: S46.011A\n",
        "3. Concussion, without loss of consciousness - ICD-10: S06.0X0A\n",
        "\n",
        "TREATMENT:\n",
        "- Cervical collar applied\n",
        "- Ibuprofen 600mg PO x1 administered\n",
        "- Cyclobenzaprine 10mg #20, 1 tablet TID as needed\n",
        "- Ibuprofen 600mg #30, 1 tablet TID with food\n",
        "\n",
        "DISCHARGE INSTRUCTIONS:\n",
        "- Rest and ice for 48 hours\n",
        "- Follow up with primary care in 5-7 days\n",
        "- Physical therapy referral provided: Austin Sports Medicine\n",
        "- Return to ED if severe headache, vomiting, confusion, or worsening symptoms\n",
        "\n",
        "Attending Physician: Dr. Amanda Foster, MD\n",
        "NPI: 1234567890\n",
        "\n",
        "CHARGES:\n",
        "ED Visit Level 4: $1,847.00\n",
        "C-Spine X-ray: $345.00\n",
        "Shoulder X-ray: $278.00\n",
        "CT Head: $1,234.00\n",
        "Medications: $47.00\n",
        "Cervical Collar: $89.00\n",
        "\n",
        "TOTAL CHARGES: $3,840.00\n",
        "\"\"\"\n",
        "    },\n",
        "    \n",
        "    \"CLM-2024-78511\": {\n",
        "        \"type\": \"homeowners_water_damage\",\n",
        "        \"policy_document\": \"\"\"\n",
        "ALLSTATE INSURANCE COMPANY\n",
        "HOMEOWNERS POLICY (HO-3)\n",
        "\n",
        "Policy Number: HOM-5567823-2024\n",
        "Effective Date: March 15, 2024\n",
        "Expiration Date: March 15, 2025\n",
        "\n",
        "NAMED INSURED:\n",
        "Name: Marcus Anthony Williams\n",
        "Co-Insured: Patricia Ann Williams\n",
        "Address: 1247 Riverside Terrace, Houston, TX 77019\n",
        "\n",
        "PROPERTY DESCRIPTION:\n",
        "Type: Single Family Dwelling\n",
        "Year Built: 1998\n",
        "Square Footage: 2,847 sq ft\n",
        "Construction: Brick Veneer\n",
        "Roof Type: Composition Shingle (replaced 2019)\n",
        "Occupancy: Owner Occupied\n",
        "\n",
        "COVERAGE:\n",
        "Coverage A - Dwelling: $425,000\n",
        "Coverage B - Other Structures: $42,500 (10%)\n",
        "Coverage C - Personal Property: $212,500 (50%)\n",
        "Coverage D - Loss of Use: $85,000 (20%)\n",
        "Coverage E - Personal Liability: $300,000\n",
        "Coverage F - Medical Payments: $5,000\n",
        "\n",
        "DEDUCTIBLES:\n",
        "All Perils: $2,500\n",
        "Wind/Hail: 2% of Coverage A ($8,500)\n",
        "Water Damage: $2,500 (subject to policy exclusions)\n",
        "\n",
        "EXCLUSIONS (Section I):\n",
        "- Flood (requires separate NFIP policy)\n",
        "- Earth movement\n",
        "- Neglect or intentional loss\n",
        "- Wear and tear, gradual deterioration\n",
        "- Water damage from lack of maintenance\n",
        "- Mold (limited coverage, $10,000 cap)\n",
        "\n",
        "ENDORSEMENTS:\n",
        "- Water Backup Coverage: $25,000 limit\n",
        "- Replacement Cost on Contents\n",
        "- Identity Theft Protection\n",
        "\n",
        "ANNUAL PREMIUM: $3,245.00\n",
        "Payment Status: Current (auto-pay)\n",
        "\"\"\",\n",
        "        \"claim_form\": \"\"\"\n",
        "FIRST NOTICE OF LOSS - PROPERTY CLAIM\n",
        "\n",
        "Claim Number: CLM-2024-78511\n",
        "Date of Loss: November 10, 2024\n",
        "Date Discovered: November 10, 2024\n",
        "Date Reported: November 11, 2024\n",
        "\n",
        "TYPE OF LOSS: Water Damage - Pipe Burst\n",
        "\n",
        "INCIDENT DESCRIPTION:\n",
        "Homeowners returned from a weekend trip on Sunday, November 10, 2024 \n",
        "at approximately 6:30 PM to discover significant water damage throughout\n",
        "the first floor of the home. Investigation revealed that a supply line\n",
        "to the upstairs master bathroom toilet had burst, likely occurring on\n",
        "Friday evening based on the extent of damage.\n",
        "\n",
        "The water traveled from the master bathroom through the ceiling/floor\n",
        "into the living room, dining room, and kitchen below. Water was still\n",
        "actively flowing when discovered. Main water supply was shut off\n",
        "immediately.\n",
        "\n",
        "IMMEDIATE ACTIONS TAKEN:\n",
        "- Water main shut off\n",
        "- ServiceMaster emergency water extraction called (arrived 8:15 PM)\n",
        "- Photos and video documentation taken\n",
        "- Moved salvageable furniture to garage\n",
        "\n",
        "AREAS AFFECTED:\n",
        "1. Master Bathroom (2nd floor) - Origin point\n",
        "2. Master Bedroom (2nd floor) - Carpet saturated near bathroom\n",
        "3. Living Room (1st floor) - Ceiling collapsed, hardwood buckled\n",
        "4. Dining Room (1st floor) - Ceiling water damage, furniture damaged\n",
        "5. Kitchen (1st floor) - Ceiling damage, cabinet water intrusion\n",
        "\n",
        "EMERGENCY SERVICES:\n",
        "ServiceMaster Restore - Houston\n",
        "Contact: James Wilson\n",
        "Work Order: SM-2024-45678\n",
        "\n",
        "IS THE HOME HABITABLE? No - electrical concerns and mold risk\n",
        "TEMPORARY HOUSING NEEDED? Yes - staying at Marriott Galleria\n",
        "\"\"\",\n",
        "        \"damage_estimate\": \"\"\"\n",
        "SCOPE OF LOSS ESTIMATE\n",
        "Prepared by: ProClaim Adjusting Services\n",
        "Date: November 15, 2024\n",
        "\n",
        "Property: 1247 Riverside Terrace, Houston, TX 77019\n",
        "Claim: CLM-2024-78511\n",
        "\n",
        "EMERGENCY SERVICES (already completed):\n",
        "- Water extraction: $2,847.00\n",
        "- Industrial dehumidifiers (5 days): $1,250.00\n",
        "- Air movers rental (5 days): $875.00\n",
        "- Antimicrobial treatment: $567.00\n",
        "Emergency Services Subtotal: $5,539.00\n",
        "\n",
        "STRUCTURAL REPAIRS:\n",
        "\n",
        "Master Bathroom (2nd Floor):\n",
        "- Remove/replace toilet supply line: $345.00\n",
        "- Remove/replace vinyl flooring (85 sf): $892.00\n",
        "- Vanity base repair: $234.00\n",
        "Bathroom Subtotal: $1,471.00\n",
        "\n",
        "Master Bedroom (2nd Floor):\n",
        "- Remove/dispose carpet and pad (180 sf): $445.00\n",
        "- Install new carpet and pad (180 sf): $1,620.00\n",
        "- Drywall repair (12 sf): $234.00\n",
        "Bedroom Subtotal: $2,299.00\n",
        "\n",
        "Living Room (1st Floor):\n",
        "- Ceiling drywall remove/replace (320 sf): $2,560.00\n",
        "- Ceiling texture match: $567.00\n",
        "- Ceiling paint: $345.00\n",
        "- Hardwood floor remove/replace (420 sf): $8,400.00\n",
        "- Baseboard remove/replace (68 lf): $612.00\n",
        "- Light fixture replacement (2): $445.00\n",
        "Living Room Subtotal: $12,929.00\n",
        "\n",
        "Dining Room (1st Floor):\n",
        "- Ceiling drywall repair (145 sf): $1,160.00\n",
        "- Ceiling paint: $234.00\n",
        "- Crown molding repair (24 lf): $312.00\n",
        "Dining Room Subtotal: $1,706.00\n",
        "\n",
        "Kitchen (1st Floor):\n",
        "- Ceiling drywall repair (95 sf): $760.00\n",
        "- Lower cabinet replacement (3 units): $2,847.00\n",
        "- Countertop section replacement: $1,234.00\n",
        "- Paint: $345.00\n",
        "Kitchen Subtotal: $5,186.00\n",
        "\n",
        "CONTENTS DAMAGE:\n",
        "- Living room sofa (leather): $2,847.00\n",
        "- Dining table and 6 chairs: $1,234.00\n",
        "- Area rug (Oriental, 9x12): $3,500.00\n",
        "- Electronics (TV, sound system): $1,892.00\n",
        "- Books and decorative items: $567.00\n",
        "Contents Subtotal: $10,040.00\n",
        "\n",
        "ADDITIONAL LIVING EXPENSES (estimated 3 weeks):\n",
        "- Hotel (21 nights @ $189): $3,969.00\n",
        "- Meals (21 days @ $75): $1,575.00\n",
        "ALE Subtotal: $5,544.00\n",
        "\n",
        "GRAND TOTAL: $44,714.00\n",
        "\n",
        "LESS DEDUCTIBLE: -$2,500.00\n",
        "\n",
        "NET CLAIM AMOUNT: $42,214.00\n",
        "\n",
        "Adjuster: Robert Martinez, CPCU\n",
        "License: TX-ADJ-78901\n",
        "\"\"\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Loaded {len(CLAIM_DOCUMENTS)} sample claim documents\")\n",
        "for claim_id, docs in CLAIM_DOCUMENTS.items():\n",
        "    print(f\"  - {claim_id}: {docs['type']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Models for Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "from enum import Enum\n",
        "import json\n",
        "\n",
        "class ClaimType(str, Enum):\n",
        "    AUTO_COLLISION = \"auto_collision\"\n",
        "    AUTO_COMPREHENSIVE = \"auto_comprehensive\"\n",
        "    HOMEOWNERS_WATER = \"homeowners_water_damage\"\n",
        "    HOMEOWNERS_FIRE = \"homeowners_fire\"\n",
        "    HOMEOWNERS_THEFT = \"homeowners_theft\"\n",
        "    LIABILITY = \"liability\"\n",
        "\n",
        "class PolicyHolder(BaseModel):\n",
        "    full_name: str = Field(description=\"Full legal name of policyholder\")\n",
        "    address: str = Field(description=\"Full address\")\n",
        "    policy_number: str = Field(description=\"Policy number\")\n",
        "    policy_effective_date: str = Field(description=\"Policy start date\")\n",
        "    policy_expiration_date: str = Field(description=\"Policy end date\")\n",
        "\n",
        "class IncidentDetails(BaseModel):\n",
        "    date_of_loss: str = Field(description=\"Date incident occurred\")\n",
        "    time_of_loss: Optional[str] = Field(description=\"Time of incident if known\")\n",
        "    location: str = Field(description=\"Where incident occurred\")\n",
        "    description: str = Field(description=\"Detailed description of what happened\")\n",
        "    weather_conditions: Optional[str] = Field(description=\"Weather at time of incident\")\n",
        "    police_report_number: Optional[str] = Field(description=\"Police report number if filed\")\n",
        "\n",
        "class InjuryDetails(BaseModel):\n",
        "    injured_party: str = Field(description=\"Name of injured person\")\n",
        "    injury_description: str = Field(description=\"Description of injuries\")\n",
        "    medical_facility: Optional[str] = Field(description=\"Where treated\")\n",
        "    diagnosis_codes: List[str] = Field(description=\"ICD-10 codes if available\")\n",
        "    medical_costs: Optional[float] = Field(description=\"Total medical costs\")\n",
        "\n",
        "class DamageItem(BaseModel):\n",
        "    item_description: str = Field(description=\"What was damaged\")\n",
        "    repair_or_replace: str = Field(description=\"Repair or Replace\")\n",
        "    estimated_cost: float = Field(description=\"Cost in dollars\")\n",
        "\n",
        "class ClaimExtraction(BaseModel):\n",
        "    claim_number: str = Field(description=\"Claim ID\")\n",
        "    claim_type: str = Field(description=\"Type of claim\")\n",
        "    date_reported: str = Field(description=\"When claim was filed\")\n",
        "    policyholder: PolicyHolder\n",
        "    incident: IncidentDetails\n",
        "    injuries: List[InjuryDetails] = Field(description=\"List of injuries if any\")\n",
        "    property_damage: List[DamageItem] = Field(description=\"List of damaged items\")\n",
        "    total_claim_amount: float = Field(description=\"Total amount claimed\")\n",
        "    deductible: float = Field(description=\"Applicable deductible\")\n",
        "    net_claim_amount: float = Field(description=\"Amount after deductible\")\n",
        "    coverage_applicable: str = Field(description=\"Which coverage applies\")\n",
        "    third_party_info: Optional[str] = Field(description=\"Other party info if applicable\")\n",
        "\n",
        "class FraudIndicators(BaseModel):\n",
        "    risk_level: str = Field(description=\"low, medium, or high\")\n",
        "    indicators_found: List[str] = Field(description=\"List of fraud indicators\")\n",
        "    inconsistencies: List[str] = Field(description=\"Inconsistencies in documents\")\n",
        "    recommendation: str = Field(description=\"SIU referral recommendation\")\n",
        "\n",
        "print(\"Data models defined for insurance claim extraction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Extraction Functions with Claude Sonnet 4.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import anthropic\n",
        "\n",
        "# Initialize Claude client\n",
        "claude = anthropic.Anthropic()\n",
        "\n",
        "def extract_claim_data(\n",
        "    claim_id: str,\n",
        "    documents: dict,\n",
        "    tracer: CERTTracer\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Extract structured data from insurance claim documents.\n",
        "    \n",
        "    Sends source documents as context for CERT Grounding Check.\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXTRACTING CLAIM: {claim_id}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Combine all document sections\n",
        "    source_chunks = []\n",
        "    combined_docs = \"\"\n",
        "    \n",
        "    for doc_type, content in documents.items():\n",
        "        if doc_type != 'type' and isinstance(content, str):\n",
        "            source_chunks.append(f\"[{doc_type.upper()}]\\n{content}\")\n",
        "            combined_docs += f\"\\n\\n=== {doc_type.upper()} ===\\n{content}\"\n",
        "    \n",
        "    print(f\"Processing {len(source_chunks)} document sections...\")\n",
        "    print(f\"Total characters: {len(combined_docs):,}\")\n",
        "    \n",
        "    # Extraction prompt\n",
        "    extraction_prompt = f\"\"\"You are an expert insurance claims analyst. Extract structured information from the following claim documents.\n",
        "\n",
        "IMPORTANT INSTRUCTIONS:\n",
        "1. Extract ONLY information that is explicitly stated in the documents\n",
        "2. If information is not found, use null or empty string\n",
        "3. Do NOT infer, assume, or hallucinate any data\n",
        "4. For costs/amounts, extract exact figures as stated\n",
        "5. Include specific dates, names, and numbers exactly as written\n",
        "\n",
        "Return a JSON object with this structure:\n",
        "{json.dumps(ClaimExtraction.model_json_schema(), indent=2)}\n",
        "\n",
        "DOCUMENTS:\n",
        "{combined_docs}\n",
        "\n",
        "Extract the structured claim data as JSON:\"\"\"\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    response = claude.messages.create(\n",
        "        model=\"claude-sonnet-4-5-20250929\",\n",
        "        max_tokens=4096,\n",
        "        messages=[{\"role\": \"user\", \"content\": extraction_prompt}]\n",
        "    )\n",
        "    \n",
        "    duration_ms = (time.time() - start_time) * 1000\n",
        "    output_text = response.content[0].text\n",
        "    \n",
        "    print(f\"\\nExtraction completed in {duration_ms/1000:.1f}s\")\n",
        "    print(f\"Tokens: {response.usage.input_tokens:,} input, {response.usage.output_tokens:,} output\")\n",
        "    \n",
        "    # Send trace to CERT with source context for Grounding Check\n",
        "    tracer.trace_extraction(\n",
        "        model=\"claude-sonnet-4-5-20250929\",\n",
        "        input_text=f\"Extract claim data from {claim_id}\",\n",
        "        output_text=output_text,\n",
        "        duration_ms=duration_ms,\n",
        "        prompt_tokens=response.usage.input_tokens,\n",
        "        completion_tokens=response.usage.output_tokens,\n",
        "        source_chunks=source_chunks,  # Critical for Grounding Check!\n",
        "        extraction_type=\"claim_data\",\n",
        "        document_id=claim_id\n",
        "    )\n",
        "    \n",
        "    # Parse JSON from response\n",
        "    try:\n",
        "        json_start = output_text.find('{')\n",
        "        json_end = output_text.rfind('}') + 1\n",
        "        extracted_data = json.loads(output_text[json_start:json_end])\n",
        "        return extracted_data\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Warning: JSON parse error - {e}\")\n",
        "        return {\"raw_response\": output_text}\n",
        "\n",
        "print(\"Claim extraction function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_fraud_risk(\n",
        "    claim_id: str,\n",
        "    documents: dict,\n",
        "    extracted_data: dict,\n",
        "    tracer: CERTTracer\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Analyze claim for potential fraud indicators.\n",
        "    \n",
        "    Looks for:\n",
        "    - Inconsistencies between documents\n",
        "    - Red flags common in fraudulent claims\n",
        "    - Timeline issues\n",
        "    - Excessive or unusual claims\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"FRAUD RISK ANALYSIS: {claim_id}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    source_chunks = []\n",
        "    combined_docs = \"\"\n",
        "    \n",
        "    for doc_type, content in documents.items():\n",
        "        if doc_type != 'type' and isinstance(content, str):\n",
        "            source_chunks.append(f\"[{doc_type.upper()}]\\n{content}\")\n",
        "            combined_docs += f\"\\n\\n=== {doc_type.upper()} ===\\n{content}\"\n",
        "    \n",
        "    fraud_prompt = f\"\"\"You are an insurance Special Investigations Unit (SIU) analyst. Review this claim for potential fraud indicators.\n",
        "\n",
        "COMMON FRAUD INDICATORS TO CHECK:\n",
        "1. Claim filed shortly after policy inception or increase in coverage\n",
        "2. Claimant has history of frequent claims (check notes)\n",
        "3. Incident occurs while claimant was away from property\n",
        "4. Damage inconsistent with described incident\n",
        "5. Inflated repair estimates or padding\n",
        "6. Delayed reporting without valid explanation\n",
        "7. Missing or reluctant witnesses\n",
        "8. Claimant financial difficulties (if mentioned)\n",
        "9. Inconsistencies between documents\n",
        "10. Pre-existing damage claimed as new\n",
        "\n",
        "EXTRACTED CLAIM DATA:\n",
        "{json.dumps(extracted_data, indent=2)}\n",
        "\n",
        "ORIGINAL DOCUMENTS:\n",
        "{combined_docs}\n",
        "\n",
        "Analyze for fraud indicators and return JSON:\n",
        "{{\n",
        "    \"risk_level\": \"low|medium|high\",\n",
        "    \"indicators_found\": [\"list of specific indicators found\"],\n",
        "    \"inconsistencies\": [\"list of inconsistencies between documents\"],\n",
        "    \"recommendation\": \"No SIU referral needed | Recommend SIU review | Urgent SIU investigation required\",\n",
        "    \"reasoning\": \"Brief explanation of assessment\"\n",
        "}}\"\"\"\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    response = claude.messages.create(\n",
        "        model=\"claude-sonnet-4-5-20250929\",\n",
        "        max_tokens=2048,\n",
        "        messages=[{\"role\": \"user\", \"content\": fraud_prompt}]\n",
        "    )\n",
        "    \n",
        "    duration_ms = (time.time() - start_time) * 1000\n",
        "    output_text = response.content[0].text\n",
        "    \n",
        "    print(f\"\\nAnalysis completed in {duration_ms/1000:.1f}s\")\n",
        "    \n",
        "    # Send trace to CERT\n",
        "    tracer.trace_extraction(\n",
        "        model=\"claude-sonnet-4-5-20250929\",\n",
        "        input_text=f\"Fraud risk analysis for {claim_id}\",\n",
        "        output_text=output_text,\n",
        "        duration_ms=duration_ms,\n",
        "        prompt_tokens=response.usage.input_tokens,\n",
        "        completion_tokens=response.usage.output_tokens,\n",
        "        source_chunks=source_chunks,\n",
        "        extraction_type=\"fraud_analysis\",\n",
        "        document_id=claim_id\n",
        "    )\n",
        "    \n",
        "    try:\n",
        "        json_start = output_text.find('{')\n",
        "        json_end = output_text.rfind('}') + 1\n",
        "        return json.loads(output_text[json_start:json_end])\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"raw_response\": output_text}\n",
        "\n",
        "print(\"Fraud analysis function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Process Claims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Claim 1: Auto Collision\n",
        "claim1_id = \"CLM-2024-78432\"\n",
        "claim1_docs = CLAIM_DOCUMENTS[claim1_id]\n",
        "\n",
        "# Extract data\n",
        "claim1_data = extract_claim_data(claim1_id, claim1_docs, tracer)\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"EXTRACTED CLAIM DATA:\")\n",
        "print(\"-\"*60)\n",
        "print(json.dumps(claim1_data, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fraud analysis for Claim 1\n",
        "claim1_fraud = analyze_fraud_risk(claim1_id, claim1_docs, claim1_data, tracer)\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"FRAUD RISK ASSESSMENT:\")\n",
        "print(\"-\"*60)\n",
        "print(json.dumps(claim1_fraud, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Claim 2: Homeowners Water Damage\n",
        "claim2_id = \"CLM-2024-78511\"\n",
        "claim2_docs = CLAIM_DOCUMENTS[claim2_id]\n",
        "\n",
        "# Extract data\n",
        "claim2_data = extract_claim_data(claim2_id, claim2_docs, tracer)\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"EXTRACTED CLAIM DATA:\")\n",
        "print(\"-\"*60)\n",
        "print(json.dumps(claim2_data, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fraud analysis for Claim 2\n",
        "claim2_fraud = analyze_fraud_risk(claim2_id, claim2_docs, claim2_data, tracer)\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"FRAUD RISK ASSESSMENT:\")\n",
        "print(\"-\"*60)\n",
        "print(json.dumps(claim2_fraud, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. CERT Dashboard - Grounding Check\n",
        "\n",
        "The most critical feature for document extraction is **Grounding Check**.\n",
        "\n",
        "### Why Grounding Check Matters\n",
        "\n",
        "When extracting data from insurance claims, we MUST verify that:\n",
        "1. Every extracted value actually exists in the source documents\n",
        "2. The model isn't \"filling in\" missing information\n",
        "3. Numbers, dates, and names are accurately transcribed\n",
        "\n",
        "### How to Use Grounding Check\n",
        "\n",
        "1. Go to CERT Dashboard → Quality → Judge\n",
        "2. Select \"Grounding Check\" as the evaluation type\n",
        "3. Run evaluation on the extraction traces\n",
        "4. Review any claims where grounding score < 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"CERT DASHBOARD - SESSION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nSession ID: {tracer.session_id}\")\n",
        "print(f\"Project: {tracer.project_name}\")\n",
        "print(f\"Traces sent: {tracer.traces_sent}\")\n",
        "print(f\"Total tokens: {tracer.total_tokens:,}\")\n",
        "\n",
        "print(f\"\\n{'─'*60}\")\n",
        "print(\"GROUNDING CHECK VERIFICATION\")\n",
        "print(f\"{'─'*60}\")\n",
        "print(\"\\nEach trace includes source document chunks as 'context'.\")\n",
        "print(\"This enables CERT's Grounding Check to verify that ALL\")\n",
        "print(\"extracted information exists in the original documents.\")\n",
        "print(\"\\nTo verify extractions:\")\n",
        "print(f\"  1. Go to: {CERT_DASHBOARD_URL}/quality\")\n",
        "print(f\"  2. Select traces from session: {tracer.session_id}\")\n",
        "print(f\"  3. Run 'Grounding Check' evaluation\")\n",
        "print(f\"  4. Review any traces with grounding score < 0.9\")\n",
        "print(f\"\\nClaims processed:\")\n",
        "print(f\"  - CLM-2024-78432 (Auto Collision)\")\n",
        "print(f\"  - CLM-2024-78511 (Water Damage)\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "### What This Notebook Demonstrates\n",
        "\n",
        "| Feature | Implementation |\n",
        "|---------|----------------|\n",
        "| **Structured Extraction** | Claude Sonnet 4.5 extracts claim data to Pydantic models |\n",
        "| **Multi-Document Processing** | Handles policy, claim form, estimates, medical records |\n",
        "| **Fraud Detection** | Identifies inconsistencies and red flags |\n",
        "| **Grounding Check** | Source context sent for hallucination detection |\n",
        "| **Real-World Complexity** | Realistic insurance documents with actual data patterns |\n",
        "\n",
        "### CERT Integration for Document Extraction\n",
        "\n",
        "The key differentiator is the `context` parameter:\n",
        "\n",
        "```python\n",
        "tracer.trace_extraction(\n",
        "    model=\"claude-sonnet-4-5-20250929\",\n",
        "    input_text=\"...\",\n",
        "    output_text=extracted_json,\n",
        "    source_chunks=document_chunks,  # Enables Grounding Check!\n",
        "    ...\n",
        ")\n",
        "```\n",
        "\n",
        "### Production Considerations\n",
        "\n",
        "1. **PDF Processing**: Use PyPDF or Document AI for real PDFs\n",
        "2. **OCR Integration**: For scanned documents\n",
        "3. **Batch Processing**: Queue-based processing for high volumes\n",
        "4. **Human-in-the-Loop**: Flag low-confidence extractions for review\n",
        "5. **Audit Trail**: CERT provides complete audit trail for compliance"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
