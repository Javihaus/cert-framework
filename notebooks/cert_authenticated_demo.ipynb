{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CERT Dashboard - Authenticated LLM Monitoring\n",
        "\n",
        "This notebook demonstrates how to use the **CERT Dashboard** as a standalone SaaS-like tool for monitoring and evaluating LLM applications.\n",
        "\n",
        "## What is CERT Dashboard?\n",
        "\n",
        "CERT (Compliance Evaluation and Reporting Tool) Dashboard is a **real-time LLM monitoring platform** that provides:\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| **Trace Collection** | Capture all LLM calls with inputs, outputs, tokens, latency |\n",
        "| **Persistent Storage** | Traces stored in your database, linked to your account |\n",
        "| **Quality Evaluations** | LLM Judge, Grounding Check, Human Review |\n",
        "| **Cost Analysis** | Track spending across providers and models |\n",
        "| **Performance Monitoring** | Latency, throughput, error rates |\n",
        "\n",
        "## Architecture\n",
        "\n",
        "```\n",
        "Your Notebook/App                    CERT Dashboard\n",
        "     │                                    │\n",
        "     │  1. Register & get API key         │\n",
        "     │ ─────────────────────────────────► │\n",
        "     │                                    │\n",
        "     │  2. Send traces with API key       │\n",
        "     │ ─────────────────────────────────► │  ──► Supabase DB\n",
        "     │    POST /api/v1/traces             │      (persistent)\n",
        "     │    Header: X-API-Key: xxx          │\n",
        "     │                                    │\n",
        "     │  3. View & evaluate in dashboard   │\n",
        "     │ ◄───────────────────────────────── │\n",
        "```\n",
        "\n",
        "## This Demo\n",
        "\n",
        "We'll run a **multi-agent document extraction pipeline** using:\n",
        "- **Claude Sonnet 4.5** - Extract structured data from Apple's 10-K SEC filing\n",
        "- **GPT-4o** - Generate an executive briefing report\n",
        "\n",
        "All LLM calls will be traced to CERT Dashboard for monitoring and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 1: CERT Dashboard Setup\n",
        "\n",
        "### 1.1 Register for an Account\n",
        "\n",
        "Before running this notebook, you need to:\n",
        "\n",
        "1. **Go to your CERT Dashboard** (e.g., `https://your-cert-dashboard.com`)\n",
        "2. **Click \"Sign In\"** in the top right\n",
        "3. **Click \"Create Account\"** or go to `/register`\n",
        "4. **Fill in your details:**\n",
        "   - Full Name\n",
        "   - Email\n",
        "   - Company (optional)\n",
        "   - Password\n",
        "5. **After registration, go to `/account`** to see your API key\n",
        "\n",
        "### 1.2 Copy Your API Key\n",
        "\n",
        "Your API key looks like: `cert_a1b2c3d4e5f6...`\n",
        "\n",
        "This key:\n",
        "- Authenticates your notebook requests\n",
        "- Links all traces to your account\n",
        "- Enables persistent storage in the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain langchain-openai langchain-anthropic langchain-community\n",
        "!pip install -q langchain-text-splitters\n",
        "!pip install -q pypdf tiktoken\n",
        "!pip install -q pydantic requests\n",
        "\n",
        "print(\"Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# =============================================================\n",
        "# CERT DASHBOARD CONFIGURATION\n",
        "# =============================================================\n",
        "\n",
        "# Your CERT Dashboard URL\n",
        "CERT_DASHBOARD_URL = \"https://dashboard.cert-framework.com\"  # Change to your URL\n",
        "\n",
        "# Your CERT API Key (get this from /account page after registration)\n",
        "if 'CERT_API_KEY' not in os.environ:\n",
        "    os.environ['CERT_API_KEY'] = getpass('Enter your CERT API Key: ')\n",
        "\n",
        "CERT_API_KEY = os.environ['CERT_API_KEY']\n",
        "\n",
        "print(f\"CERT Dashboard: {CERT_DASHBOARD_URL}\")\n",
        "print(f\"API Key: {CERT_API_KEY[:20]}...\" if len(CERT_API_KEY) > 20 else f\"API Key: {CERT_API_KEY}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# LLM API KEYS\n",
        "# =============================================================\n",
        "\n",
        "# Set your LLM provider API keys\n",
        "if 'OPENAI_API_KEY' not in os.environ:\n",
        "    os.environ['OPENAI_API_KEY'] = getpass('Enter your OpenAI API key: ')\n",
        "\n",
        "if 'ANTHROPIC_API_KEY' not in os.environ:\n",
        "    os.environ['ANTHROPIC_API_KEY'] = getpass('Enter your Anthropic API key: ')\n",
        "\n",
        "print(\"LLM API keys configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 2: CERT Tracer with Authentication\n",
        "\n",
        "The `CERTTracer` class sends LLM call data to your CERT Dashboard.\n",
        "\n",
        "**Key features:**\n",
        "- Uses `X-API-Key` header for authentication\n",
        "- Traces are stored persistently in your database\n",
        "- Supports source context for Grounding Check evaluation\n",
        "- No third-party telemetry dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import List, Optional, Dict, Any\n",
        "\n",
        "class CERTTracer:\n",
        "    \"\"\"\n",
        "    Authenticated tracer for CERT Dashboard.\n",
        "    \n",
        "    Sends LLM call traces to your CERT Dashboard with:\n",
        "    - API key authentication (traces linked to your account)\n",
        "    - Persistent storage in database\n",
        "    - Support for Grounding Check (source context)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dashboard_url: str, api_key: str, project_name: str = \"default\"):\n",
        "        \"\"\"\n",
        "        Initialize the CERT tracer.\n",
        "        \n",
        "        Args:\n",
        "            dashboard_url: Your CERT Dashboard URL (e.g., https://your-cert.com)\n",
        "            api_key: Your CERT API key (from /account page)\n",
        "            project_name: Name for this project/experiment\n",
        "        \"\"\"\n",
        "        self.endpoint = f\"{dashboard_url.rstrip('/')}/api/v1/traces\"\n",
        "        self.api_key = api_key\n",
        "        self.project_name = project_name\n",
        "        self.session_id = str(uuid.uuid4())[:8]\n",
        "        self.traces_sent = 0\n",
        "        \n",
        "    def _get_headers(self) -> Dict[str, str]:\n",
        "        \"\"\"Get request headers with authentication.\"\"\"\n",
        "        return {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"X-API-Key\": self.api_key  # Authentication header\n",
        "        }\n",
        "    \n",
        "    def send_trace(self, trace_data: dict) -> bool:\n",
        "        \"\"\"\n",
        "        Send a single trace to CERT Dashboard.\n",
        "        \n",
        "        Returns True if successful, False otherwise.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                self.endpoint,\n",
        "                json={\"traces\": [trace_data]},\n",
        "                headers=self._get_headers(),\n",
        "                timeout=10\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                self.traces_sent += 1\n",
        "                storage = \"database\" if result.get('stored_in_db') else \"memory\"\n",
        "                print(f\"  [CERT] Trace #{self.traces_sent} sent -> stored in {storage}\")\n",
        "                return True\n",
        "            elif response.status_code == 401:\n",
        "                print(f\"  [CERT] Authentication failed. Check your API key.\")\n",
        "                return False\n",
        "            else:\n",
        "                print(f\"  [CERT] Error {response.status_code}: {response.text[:200]}\")\n",
        "                return False\n",
        "                \n",
        "        except requests.exceptions.ConnectionError:\n",
        "            print(f\"  [CERT] Connection failed. Is the dashboard running?\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"  [CERT] Error: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def trace_llm_call(\n",
        "        self,\n",
        "        provider: str,\n",
        "        model: str,\n",
        "        input_text: str,\n",
        "        output_text: str,\n",
        "        duration_ms: float,\n",
        "        prompt_tokens: int = 0,\n",
        "        completion_tokens: int = 0,\n",
        "        context: Optional[List[str]] = None,\n",
        "        status: str = \"ok\",\n",
        "        metadata: Optional[Dict[str, Any]] = None\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Record an LLM call trace and send to CERT Dashboard.\n",
        "        \n",
        "        Args:\n",
        "            provider: LLM provider (e.g., \"anthropic\", \"openai\")\n",
        "            model: Model name (e.g., \"claude-sonnet-4-5-20250929\")\n",
        "            input_text: The prompt/input sent to the LLM\n",
        "            output_text: The response from the LLM\n",
        "            duration_ms: Time taken for the call in milliseconds\n",
        "            prompt_tokens: Number of input tokens\n",
        "            completion_tokens: Number of output tokens\n",
        "            context: Source documents/chunks for Grounding Check evaluation\n",
        "            status: \"ok\" or \"error\"\n",
        "            metadata: Additional metadata to include\n",
        "            \n",
        "        Returns:\n",
        "            The trace dictionary that was sent\n",
        "        \"\"\"\n",
        "        trace = {\n",
        "            \"id\": f\"{self.session_id}-{str(uuid.uuid4())[:8]}\",\n",
        "            \"provider\": provider,\n",
        "            \"model\": model,\n",
        "            \"input\": input_text,\n",
        "            \"output\": output_text,\n",
        "            \"promptTokens\": prompt_tokens,\n",
        "            \"completionTokens\": completion_tokens,\n",
        "            \"durationMs\": round(duration_ms, 2),\n",
        "            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "            \"status\": status,\n",
        "            \"metadata\": {\n",
        "                \"project\": self.project_name,\n",
        "                \"session_id\": self.session_id,\n",
        "                **(metadata or {})\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Add context for Grounding Check evaluation\n",
        "        # This allows CERT to verify outputs are grounded in source documents\n",
        "        if context:\n",
        "            trace[\"context\"] = context\n",
        "            \n",
        "        self.send_trace(trace)\n",
        "        return trace\n",
        "    \n",
        "    def test_connection(self) -> bool:\n",
        "        \"\"\"Test the connection and authentication to CERT Dashboard.\"\"\"\n",
        "        print(f\"Testing connection to: {self.endpoint}\")\n",
        "        print(f\"Using API key: {self.api_key[:20]}...\")\n",
        "        \n",
        "        try:\n",
        "            # Send a test trace\n",
        "            test_trace = {\n",
        "                \"id\": f\"test-{str(uuid.uuid4())[:8]}\",\n",
        "                \"provider\": \"test\",\n",
        "                \"model\": \"connection-test\",\n",
        "                \"input\": \"Connection test\",\n",
        "                \"output\": \"Test successful\",\n",
        "                \"promptTokens\": 0,\n",
        "                \"completionTokens\": 0,\n",
        "                \"durationMs\": 0,\n",
        "                \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "                \"metadata\": {\"test\": True}\n",
        "            }\n",
        "            \n",
        "            response = requests.post(\n",
        "                self.endpoint,\n",
        "                json={\"traces\": [test_trace]},\n",
        "                headers=self._get_headers(),\n",
        "                timeout=10\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                print(f\"Connection successful!\")\n",
        "                print(f\"  Traces received: {result.get('received', 'unknown')}\")\n",
        "                print(f\"  Stored in DB: {result.get('stored_in_db', False)}\")\n",
        "                print(f\"  User ID: {result.get('user_id', 'anonymous')}\")\n",
        "                return True\n",
        "            elif response.status_code == 401:\n",
        "                print(f\"Authentication failed!\")\n",
        "                print(f\"  Please check your API key at /account\")\n",
        "                return False\n",
        "            else:\n",
        "                print(f\"Connection failed: {response.status_code}\")\n",
        "                print(f\"  Response: {response.text[:200]}\")\n",
        "                return False\n",
        "                \n",
        "        except requests.exceptions.ConnectionError:\n",
        "            print(f\"Connection failed: Could not reach {self.endpoint}\")\n",
        "            print(f\"  Is your CERT Dashboard running?\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Connection failed: {e}\")\n",
        "            return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# INITIALIZE CERT TRACER\n",
        "# =============================================================\n",
        "\n",
        "cert_tracer = CERTTracer(\n",
        "    dashboard_url=CERT_DASHBOARD_URL,\n",
        "    api_key=CERT_API_KEY,\n",
        "    project_name=\"apple-10k-extraction\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CERT Dashboard - Authenticated Tracer\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Dashboard URL: {CERT_DASHBOARD_URL}\")\n",
        "print(f\"Project: {cert_tracer.project_name}\")\n",
        "print(f\"Session ID: {cert_tracer.session_id}\")\n",
        "print()\n",
        "print(\"Testing connection...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "connection_ok = cert_tracer.test_connection()\n",
        "\n",
        "if connection_ok:\n",
        "    print()\n",
        "    print(\"View your traces at:\")\n",
        "    print(f\"  {CERT_DASHBOARD_URL}/quality\")\n",
        "    print(f\"  {CERT_DASHBOARD_URL}/operational/observability\")\n",
        "else:\n",
        "    print()\n",
        "    print(\"Troubleshooting:\")\n",
        "    print(\"  1. Verify your CERT Dashboard is running\")\n",
        "    print(\"  2. Check your API key at /account\")\n",
        "    print(\"  3. Ensure the URL is correct\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 3: Load Document for Extraction\n",
        "\n",
        "We'll extract data from Apple's 10-K SEC filing as a demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For Google Colab: Upload the PDF\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"Running in Google Colab\")\n",
        "    print(\"Please upload Apple's 10-K PDF file:\")\n",
        "    print(\"(Download from: https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000320193&type=10-K)\")\n",
        "    uploaded = files.upload()\n",
        "    PDF_PATH = list(uploaded.keys())[0]\n",
        "    print(f\"\\nUploaded: {PDF_PATH}\")\n",
        "except ImportError:\n",
        "    # Running locally\n",
        "    print(\"Running locally - specify the PDF path:\")\n",
        "    PDF_PATH = input(\"Enter path to 10-K PDF: \") or \"apple_10k.pdf\"\n",
        "    print(f\"Using: {PDF_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load the PDF\n",
        "print(f\"Loading PDF: {PDF_PATH}\")\n",
        "loader = PyPDFLoader(PDF_PATH)\n",
        "documents = loader.load()\n",
        "print(f\"Loaded {len(documents)} pages\")\n",
        "\n",
        "# Split into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=4000,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Split into {len(chunks)} chunks\")\n",
        "\n",
        "# Preview first chunk\n",
        "print(f\"\\nFirst chunk preview ({len(chunks[0].page_content)} chars):\")\n",
        "print(\"-\" * 40)\n",
        "print(chunks[0].page_content[:500] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 4: Define Data Models\n",
        "\n",
        "Pydantic models for structured extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "\n",
        "class FinancialMetrics(BaseModel):\n",
        "    \"\"\"Key financial metrics from 10-K\"\"\"\n",
        "    total_revenue: Optional[str] = Field(description=\"Total net revenue/sales\")\n",
        "    net_income: Optional[str] = Field(description=\"Net income\")\n",
        "    gross_margin: Optional[str] = Field(description=\"Gross margin percentage\")\n",
        "    operating_income: Optional[str] = Field(description=\"Operating income\")\n",
        "    eps: Optional[str] = Field(description=\"Earnings per share (diluted)\")\n",
        "    total_assets: Optional[str] = Field(description=\"Total assets\")\n",
        "    total_debt: Optional[str] = Field(description=\"Total debt/liabilities\")\n",
        "    cash_and_equivalents: Optional[str] = Field(description=\"Cash and cash equivalents\")\n",
        "\n",
        "class BusinessSegments(BaseModel):\n",
        "    \"\"\"Revenue by segment\"\"\"\n",
        "    iphone_revenue: Optional[str] = Field(description=\"iPhone revenue\")\n",
        "    mac_revenue: Optional[str] = Field(description=\"Mac revenue\")\n",
        "    ipad_revenue: Optional[str] = Field(description=\"iPad revenue\")\n",
        "    wearables_revenue: Optional[str] = Field(description=\"Wearables, Home and Accessories revenue\")\n",
        "    services_revenue: Optional[str] = Field(description=\"Services revenue\")\n",
        "\n",
        "class RiskFactors(BaseModel):\n",
        "    \"\"\"Key risk factors\"\"\"\n",
        "    risks: List[str] = Field(description=\"List of key risk factors\")\n",
        "\n",
        "class ExtractedData(BaseModel):\n",
        "    \"\"\"Complete extracted data from 10-K\"\"\"\n",
        "    company_name: str = Field(description=\"Company name\")\n",
        "    fiscal_year: str = Field(description=\"Fiscal year\")\n",
        "    financial_metrics: FinancialMetrics\n",
        "    business_segments: BusinessSegments\n",
        "    risk_factors: RiskFactors\n",
        "    business_overview: str = Field(description=\"Brief business description\")\n",
        "    key_developments: List[str] = Field(description=\"Key developments\")\n",
        "\n",
        "print(\"Data models defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 5: Initialize LLM Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Claude Sonnet 4.5 for extraction (excellent at structured data)\n",
        "extractor_llm = ChatAnthropic(\n",
        "    model=\"claude-sonnet-4-5-20250929\",\n",
        "    temperature=0,\n",
        "    max_tokens=4096\n",
        ")\n",
        "\n",
        "# GPT-4o for report generation (strong narrative writing)\n",
        "report_llm = ChatOpenAI(\n",
        "    model=\"gpt-4o\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=2048\n",
        ")\n",
        "\n",
        "print(\"LLM Models:\")\n",
        "print(\"  Agent 1 (Extractor): Claude Sonnet 4.5\")\n",
        "print(\"  Agent 2 (Reporter):  GPT-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 6: Agent 1 - Document Extractor (Claude Sonnet 4.5)\n",
        "\n",
        "This agent extracts structured financial data from the 10-K filing.\n",
        "\n",
        "**CERT Features Used:**\n",
        "- `context` parameter: Sends source document chunks for **Grounding Check** evaluation\n",
        "- Token tracking: Monitors input/output tokens for cost analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import json\n",
        "\n",
        "# Extraction prompt\n",
        "extraction_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert financial analyst specializing in SEC filings.\n",
        "Extract key information from Apple's 10-K filing and return it as valid JSON.\n",
        "\n",
        "Extract:\n",
        "- Company name and fiscal year\n",
        "- Financial metrics (revenue, net income, margins, EPS, assets, debt, cash)\n",
        "- Revenue by segment (iPhone, Mac, iPad, Wearables, Services)\n",
        "- Top 5 risk factors\n",
        "- Brief business overview (2-3 sentences)\n",
        "- Key developments (3-5 bullet points)\n",
        "\n",
        "Use null for missing values. Include units (e.g., \"$394.3 billion\").\n",
        "\n",
        "Return ONLY valid JSON matching this schema:\n",
        "{schema}\"\"\"),\n",
        "    (\"human\", \"\"\"Analyze these sections from Apple's 10-K:\n",
        "\n",
        "---\n",
        "{document_text}\n",
        "---\n",
        "\n",
        "Return extracted data as JSON:\"\"\")\n",
        "])\n",
        "\n",
        "print(\"Extraction prompt configured.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_with_tracing(chunks, llm, prompt, tracer):\n",
        "    \"\"\"\n",
        "    Extract data from document chunks with CERT tracing.\n",
        "    \n",
        "    Sends source chunks as 'context' for Grounding Check evaluation,\n",
        "    which verifies extracted data comes from source documents.\n",
        "    \"\"\"\n",
        "    # Prepare source chunks (for Grounding Check)\n",
        "    source_chunks = [chunk.page_content for chunk in chunks[:30]]\n",
        "    combined_text = \"\\n\\n---\\n\\n\".join(source_chunks)\n",
        "    \n",
        "    # Truncate if needed\n",
        "    if len(combined_text) > 100000:\n",
        "        combined_text = combined_text[:100000]\n",
        "        source_chunks = source_chunks[:15]\n",
        "    \n",
        "    print(f\"Processing {len(combined_text):,} characters\")\n",
        "    print(f\"Sending {len(source_chunks)} source chunks for Grounding Check\")\n",
        "    \n",
        "    # Create chain and run\n",
        "    chain = prompt | llm\n",
        "    \n",
        "    start_time = time.time()\n",
        "    response = chain.invoke({\n",
        "        \"schema\": ExtractedData.model_json_schema(),\n",
        "        \"document_text\": combined_text\n",
        "    })\n",
        "    duration_ms = (time.time() - start_time) * 1000\n",
        "    \n",
        "    # Get token counts\n",
        "    prompt_tokens = 0\n",
        "    completion_tokens = 0\n",
        "    if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
        "        prompt_tokens = response.usage_metadata.get('input_tokens', 0)\n",
        "        completion_tokens = response.usage_metadata.get('output_tokens', 0)\n",
        "    \n",
        "    print(f\"\\nExtraction complete in {duration_ms/1000:.1f}s\")\n",
        "    print(f\"Tokens: {prompt_tokens:,} input, {completion_tokens:,} output\")\n",
        "    \n",
        "    # Send trace to CERT Dashboard with source context\n",
        "    tracer.trace_llm_call(\n",
        "        provider=\"anthropic\",\n",
        "        model=\"claude-sonnet-4-5-20250929\",\n",
        "        input_text=f\"Extract financial data from Apple 10-K ({len(combined_text):,} chars)\",\n",
        "        output_text=response.content[:1000] + \"...\" if len(response.content) > 1000 else response.content,\n",
        "        duration_ms=duration_ms,\n",
        "        prompt_tokens=prompt_tokens,\n",
        "        completion_tokens=completion_tokens,\n",
        "        context=source_chunks,  # Enable Grounding Check!\n",
        "        metadata={\"task\": \"extraction\", \"doc_type\": \"10-K\"}\n",
        "    )\n",
        "    \n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"AGENT 1: Document Extractor (Claude Sonnet 4.5)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nExtracting from 10-K filing...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Run extraction\n",
        "extraction_result = extract_with_tracing(\n",
        "    chunks, \n",
        "    extractor_llm, \n",
        "    extraction_prompt,\n",
        "    cert_tracer\n",
        ")\n",
        "\n",
        "# Parse JSON\n",
        "try:\n",
        "    json_start = extraction_result.find('{')\n",
        "    json_end = extraction_result.rfind('}') + 1\n",
        "    json_str = extraction_result[json_start:json_end]\n",
        "    extracted_data = json.loads(json_str)\n",
        "    print(\"\\nExtraction successful!\")\n",
        "except json.JSONDecodeError:\n",
        "    print(\"\\nWarning: Could not parse JSON, using raw response\")\n",
        "    extracted_data = {\"raw_response\": extraction_result}\n",
        "\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"EXTRACTED DATA:\")\n",
        "print(\"-\" * 60)\n",
        "print(json.dumps(extracted_data, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 7: Agent 2 - Report Generator (GPT-4o)\n",
        "\n",
        "This agent generates an executive briefing from the extracted data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Report generation prompt\n",
        "report_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a senior financial analyst writing an executive briefing.\n",
        "Create a concise, professional report with:\n",
        "1. Key financial performance metrics\n",
        "2. Notable trends and changes\n",
        "3. Material risks summary\n",
        "4. Brief outlook\n",
        "\n",
        "Use professional language, clear sections, and bullet points.\"\"\"),\n",
        "    (\"human\", \"\"\"Based on this extracted Apple 10-K data, generate an executive briefing (500-700 words):\n",
        "\n",
        "EXTRACTED DATA:\n",
        "{extracted_data}\n",
        "\n",
        "Generate the report:\"\"\")\n",
        "])\n",
        "\n",
        "print(\"Report prompt configured.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"AGENT 2: Report Generator (GPT-4o)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nGenerating executive briefing...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Create chain and run\n",
        "report_chain = report_prompt | report_llm\n",
        "report_input = json.dumps(extracted_data, indent=2)\n",
        "\n",
        "start_time = time.time()\n",
        "report_response = report_chain.invoke({\"extracted_data\": report_input})\n",
        "duration_ms = (time.time() - start_time) * 1000\n",
        "\n",
        "final_report = report_response.content\n",
        "\n",
        "# Get token counts\n",
        "prompt_tokens = 0\n",
        "completion_tokens = 0\n",
        "if hasattr(report_response, 'usage_metadata') and report_response.usage_metadata:\n",
        "    prompt_tokens = report_response.usage_metadata.get('input_tokens', 0)\n",
        "    completion_tokens = report_response.usage_metadata.get('output_tokens', 0)\n",
        "\n",
        "print(f\"\\nReport generated in {duration_ms/1000:.1f}s\")\n",
        "print(f\"Tokens: {prompt_tokens:,} input, {completion_tokens:,} output\")\n",
        "\n",
        "# Send trace to CERT Dashboard\n",
        "cert_tracer.trace_llm_call(\n",
        "    provider=\"openai\",\n",
        "    model=\"gpt-4o\",\n",
        "    input_text=\"Generate executive briefing from extracted Apple 10-K data\",\n",
        "    output_text=final_report[:1000] + \"...\" if len(final_report) > 1000 else final_report,\n",
        "    duration_ms=duration_ms,\n",
        "    prompt_tokens=prompt_tokens,\n",
        "    completion_tokens=completion_tokens,\n",
        "    metadata={\"task\": \"report_generation\", \"doc_type\": \"executive_briefing\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL EXECUTIVE BRIEFING REPORT\")\n",
        "print(\"=\" * 60)\n",
        "print(final_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 8: View Results in CERT Dashboard\n",
        "\n",
        "Your traces are now stored in CERT Dashboard. Here's what you can do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"CERT DASHBOARD - Next Steps\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nSession ID: {cert_tracer.session_id}\")\n",
        "print(f\"Traces sent: {cert_tracer.traces_sent}\")\n",
        "print()\n",
        "print(\"View your traces:\")\n",
        "print(f\"  {CERT_DASHBOARD_URL}/quality\")\n",
        "print()\n",
        "print(\"Available evaluations:\")\n",
        "print()\n",
        "print(\"1. LLM Judge (/quality/judge)\")\n",
        "print(\"   - Automated quality scoring using another LLM\")\n",
        "print(\"   - Evaluates: Accuracy, Completeness, Coherence, Relevance\")\n",
        "print()\n",
        "print(\"2. Grounding Check (/quality/judge)\")\n",
        "print(\"   - Verifies outputs are grounded in source documents\")\n",
        "print(\"   - Perfect for document extraction tasks!\")\n",
        "print(\"   - Uses the 'context' field we sent with traces\")\n",
        "print()\n",
        "print(\"3. Human Review (/quality/review)\")\n",
        "print(\"   - Manual review interface for quality assurance\")\n",
        "print(\"   - Pass/Fail/Review decisions\")\n",
        "print()\n",
        "print(\"Operational monitoring:\")\n",
        "print(f\"  {CERT_DASHBOARD_URL}/operational/performance - Latency & throughput\")\n",
        "print(f\"  {CERT_DASHBOARD_URL}/operational/costs - Cost analysis by model\")\n",
        "print(f\"  {CERT_DASHBOARD_URL}/operational/observability - Full trace details\")\n",
        "print()\n",
        "print(\"Account management:\")\n",
        "print(f\"  {CERT_DASHBOARD_URL}/account - View API key & usage stats\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 9: Save Results Locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Create output\n",
        "output = {\n",
        "    \"metadata\": {\n",
        "        \"source_document\": PDF_PATH,\n",
        "        \"extraction_model\": \"claude-sonnet-4-5-20250929\",\n",
        "        \"report_model\": \"gpt-4o\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"cert_session_id\": cert_tracer.session_id,\n",
        "        \"cert_traces_sent\": cert_tracer.traces_sent\n",
        "    },\n",
        "    \"extracted_data\": extracted_data,\n",
        "    \"executive_report\": final_report\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "output_filename = f\"apple_10k_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(output_filename, 'w') as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "\n",
        "print(f\"Results saved to: {output_filename}\")\n",
        "\n",
        "# Download in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(output_filename)\n",
        "except ImportError:\n",
        "    print(f\"(Running locally - file saved to current directory)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "### What We Did\n",
        "\n",
        "1. **Registered** for a CERT Dashboard account and got an API key\n",
        "2. **Configured** the `CERTTracer` with authentication\n",
        "3. **Ran** a multi-agent pipeline:\n",
        "   - **Claude Sonnet 4.5** extracted structured data from Apple's 10-K\n",
        "   - **GPT-4o** generated an executive briefing report\n",
        "4. **Traced** all LLM calls to CERT Dashboard with:\n",
        "   - Source context for Grounding Check\n",
        "   - Token counts for cost analysis\n",
        "   - Timing for performance monitoring\n",
        "\n",
        "### CERT Dashboard Features\n",
        "\n",
        "| Feature | Description | URL |\n",
        "|---------|-------------|-----|\n",
        "| Quality Overview | Summary of all evaluations | `/quality` |\n",
        "| LLM Judge | Automated quality scoring | `/quality/judge` |\n",
        "| Grounding Check | Verify outputs match sources | `/quality/judge` |\n",
        "| Human Review | Manual quality review | `/quality/review` |\n",
        "| Performance | Latency & throughput metrics | `/operational/performance` |\n",
        "| Cost Analysis | Spending by model/provider | `/operational/costs` |\n",
        "| Observability | Full trace details | `/operational/observability` |\n",
        "| Account | API key & usage stats | `/account` |\n",
        "\n",
        "### Authentication Flow\n",
        "\n",
        "```python\n",
        "# 1. Get your API key from /account after registration\n",
        "CERT_API_KEY = \"cert_a1b2c3d4e5f6...\"\n",
        "\n",
        "# 2. Initialize tracer\n",
        "tracer = CERTTracer(\n",
        "    dashboard_url=\"https://your-cert-dashboard.com\",\n",
        "    api_key=CERT_API_KEY,\n",
        "    project_name=\"my-project\"\n",
        ")\n",
        "\n",
        "# 3. Trace LLM calls\n",
        "tracer.trace_llm_call(\n",
        "    provider=\"openai\",\n",
        "    model=\"gpt-4o\",\n",
        "    input_text=\"...\",\n",
        "    output_text=\"...\",\n",
        "    duration_ms=1234,\n",
        "    prompt_tokens=100,\n",
        "    completion_tokens=200,\n",
        "    context=[\"source1\", \"source2\"]  # For Grounding Check\n",
        ")\n",
        "```\n",
        "\n",
        "### Benefits of Persistent Storage\n",
        "\n",
        "- **Traces persist** across page refreshes and sessions\n",
        "- **Linked to your account** for team collaboration\n",
        "- **Historical analysis** of LLM performance over time\n",
        "- **Cost tracking** across all your projects"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
