<div align="center">

# CERT Framework

### Production LLM Monitoring + EU AI Act Compliance

<img src="docs/dashboard-hero.png" alt="CERT Dashboard" width="100%" />

---

[![PyPI](https://img.shields.io/pypi/v/cert-framework?color=4B8BBE&logo=python&logoColor=white)](https://pypi.org/project/cert-framework/)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg?logo=apache&logoColor=white)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue?logo=python&logoColor=white)](https://www.python.org)
[![Tests](https://img.shields.io/badge/tests-passing-success?logo=pytest&logoColor=white)](https://github.com/javier/cert-framework/actions)
[![Code Style](https://img.shields.io/badge/code%20style-ruff-000000.svg?logo=ruff&logoColor=white)](https://github.com/astral-sh/ruff)
[![Downloads](https://img.shields.io/pypi/dm/cert-framework?color=blue&logo=pypi&logoColor=white)](https://pypi.org/project/cert-framework/)

**[Documentation](https://cert-framework.readthedocs.io)** â€¢ 
**[Quick Start](#quick-start)** â€¢ 
**[Dashboard Demo](https://cert-demo.vercel.app)** â€¢ 
**[EU AI Act Guide](docs/compliance.md)**

</div>

---

## ğŸ¯ The Problem

<table>
<tr>
<td width="50%">

### Current State
Companies deploy LLMs with **two disconnected systems**:

**For Engineers:**
- Langfuse / Arize
- Monitor latency, tokens, costs
- Debug production issues

**For Compliance:**
- OneTrust / Vanta  
- Policy documentation
- Manual sampling of traces

</td>
<td width="50%">

### Result
âŒ Engineers log 10,000 inferences  
âŒ Legal reviews 50 manually  
âŒ No connection between systems  
âŒ EU AI Act requires 100% coverage  
âŒ Manual compliance costs â‚¬29K/year  

**The gap:** Monitoring traces never become compliance evidence.

</td>
</tr>
</table>

## âš¡ CERT Solution

<div align="center">

```mermaid
graph LR
    A[Production LLM] -->|logged automatically| B[CERT Measurement]
    B -->|confidence scores| C[Engineering Dashboard]
    B -->|same data| D[Article 15 Report]
    style B fill:#4B8BBE
    style C fill:#68D391
    style D fill:#68D391
```

</div>

**One tool. One dataset. Automatic compliance.**

Your production monitoring generates Article 15 documentation as a side effect.

---

## ğŸ”¬ Validated on Stanford SQuAD v2.0

<table>
<tr>
<td align="center" width="33%">
<img src="https://img.shields.io/badge/ROC%20AUC-0.961-success?style=for-the-badge" />
<br/>
<sub>Near-perfect discrimination</sub>
</td>
<td align="center" width="33%">
<img src="https://img.shields.io/badge/Accuracy-95.3%25-success?style=for-the-badge" />
<br/>
<sub>At optimal threshold (0.46)</sub>
</td>
<td align="center" width="33%">
<img src="https://img.shields.io/badge/Separation-0.247Ïƒ-success?style=for-the-badge" />
<br/>
<sub>Cohen's d effect size</sub>
</td>
</tr>
</table>

<details>
<summary><b>ğŸ“Š View validation details</b></summary>

Dataset: Stanford Question Answering Dataset (SQuAD v2.0)  
License: CC BY-SA 4.0  
Citation: Rajpurkar et al., 2018

The measurement system reliably distinguishes accurate LLM outputs from hallucinations in production.

</details>

---

## ğŸš€ Quick Start

### Installation

```bash
pip install cert-framework
```

### Measure LLM Accuracy

```python
from cert import measure

result = measure(
    text1="Apple's Q4 revenue was $450 billion",  # LLM output
    text2="Apple reported Q4 revenue of $89.5B"   # Ground truth
)

print(f"Confidence: {result.confidence:.2f}")  # 0.42 - flags hallucination
```

<div align="center">

**[ğŸ“– Full Documentation](docs/)** â€¢ **[ğŸ’» Code Examples](examples/)** â€¢ **[ğŸ¨ Dashboard Setup](dashboard/)**

</div>

---

## ğŸ“‹ EU AI Act Compliance Coverage

<table>
<tr>
<td width="50%">

### Articles Covered
- âœ… **Article 15** - Accuracy, robustness, cybersecurity
- âœ… **Article 19** - Automatic logging requirements
- âœ… **Annex IV** - Technical documentation (all 9 sections)
- âœ… **Annex VII** - Conformity assessment

</td>
<td width="50%">

### Generated Automatically
- ğŸ“„ Technical documentation
- ğŸ“Š Performance metrics  
- ğŸ” Audit trails (100% coverage)
- âœï¸ Declaration of Conformity

</td>
</tr>
</table>

**Deadline:** August 2, 2025 for high-risk AI systems

---

## ğŸ—ï¸ Architecture

CERT combines two measurement components:

| Component | Weight | What It Catches | Correlation |
|-----------|--------|-----------------|-------------|
| **Semantic Similarity** | 50% | Topic drift, paraphrasing errors | r = 0.644 |
| **Term Grounding** | 50% | Factual hallucinations, number errors | r = 0.899 |

**Combined score:** `confidence = 0.5 Ã— semantic + 0.5 Ã— grounding`

<details>
<summary><b>ğŸ”¬ Why this works</b></summary>

Semantic similarity alone misses factual errors (high similarity, wrong facts).  
Grounding alone misses paraphrasing (low overlap, correct meaning).  
Together they provide robust accuracy measurement validated on SQuAD v2.

</details>

---

## ğŸ¨ Dashboard

<div align="center">

<img src="docs/dashboard-metrics.png" alt="Metrics View" width="45%" />
<img src="docs/dashboard-traces.png" alt="Failed Traces" width="45%" />

**Interactive visualization â€¢ Real-time compliance status â€¢ Failed trace analysis**

</div>

```bash
cd dashboard && npm install && npm run dev
# Upload evaluation_results.json â†’ instant compliance view
```

---

## ğŸ†š Comparison

<table>
<thead>
<tr>
<th>Capability</th>
<th>Langfuse / Arize</th>
<th>OneTrust / Vanta</th>
<th>CERT</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLM trace monitoring</td>
<td align="center">âœ…</td>
<td align="center">âŒ</td>
<td align="center">âœ…</td>
</tr>
<tr>
<td>EU AI Act compliance</td>
<td align="center">âŒ</td>
<td align="center">âœ…</td>
<td align="center">âœ…</td>
</tr>
<tr>
<td>Developer SDK</td>
<td align="center">âœ…</td>
<td align="center">âŒ</td>
<td align="center">âœ…</td>
</tr>
<tr>
<td>Accuracy measurement</td>
<td align="center">Manual</td>
<td align="center">âŒ</td>
<td align="center">Automatic</td>
</tr>
<tr>
<td>Open source</td>
<td align="center">âœ…</td>
<td align="center">âŒ</td>
<td align="center">âœ…</td>
</tr>
<tr>
<td>Cost (self-hosted)</td>
<td align="center">Free</td>
<td align="center">â‚¬50K+/year</td>
<td align="center">Free</td>
</tr>
</tbody>
</table>

**Use together:** CERT for AI measurement, Langfuse for debugging, OneTrust for org-wide policies.

---

## ğŸ—ºï¸ Roadmap

<table>
<tr>
<td width="25%">

**Q4 2025**  
âœ… Core engine  
âœ… SQuAD validation  
âœ… TypeScript dashboard  
âœ… Compliance reports

</td>
<td width="25%">

**Q1 2026**  
ğŸš§ Multi-language  
ğŸš§ Langfuse integration  
ğŸš§ Grafana templates  
ğŸš§ Hosted SaaS

</td>
<td width="25%">

**Q2 2026**  
ğŸ“‹ Domain benchmarks  
ğŸ“‹ Auto-calibration  
ğŸ“‹ Multi-modal support  
ğŸ“‹ Real-time monitoring

</td>
<td width="25%">

**Q3 2026**  
ğŸ”® Circuit breakers  
ğŸ”® Enterprise features  
ğŸ”® Integration marketplace  
ğŸ”® Drift detection

</td>
</tr>
</table>

---

<div align="center">

## ğŸ¤ Contributing

We welcome contributions! Check [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**[ğŸ› Report Bug](https://github.com/javier/cert-framework/issues)** â€¢ 
**[ğŸ’¡ Request Feature](https://github.com/javier/cert-framework/discussions)** â€¢ 
**[ğŸ“– Improve Docs](docs/)**

---

## ğŸ“„ License

Apache 2.0 - see [LICENSE](LICENSE)

Commercial use âœ… â€¢ Modification âœ… â€¢ Distribution âœ… â€¢ Private use âœ…

---

## ğŸ“ Contact

**Javier Marin** â€¢ [LinkedIn](https://linkedin.com/in/javiermarinvalenzuela) â€¢ [Twitter](https://x.com/jamarinval)  
**Email:** javier@jmarin.info

---

### Built for teams shipping AI under EU regulation

**Start measuring:** `pip install cert-framework`

[![Star on GitHub](https://img.shields.io/github/stars/javier/cert-framework?style=social)](https://github.com/javier/cert-framework)

</div>
