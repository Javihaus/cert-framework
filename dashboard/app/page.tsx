'use client';

import { useState } from 'react';
import {
  Box,
  Button,
  Grid,
  Text,
  Code,
  Link,
} from '@chakra-ui/react';
import { MdCheckCircle, MdCancel, MdAssessment, MdList, MdLock } from 'react-icons/md';
import Navigation from '@/components/Navigation';
import FileUpload from '@/components/FileUpload';
import MetricCard from '@/components/MetricCard';
import Card from '@/components/Card';
import StatusBanner from '@/components/StatusBanner';
import QuickActions from '@/components/QuickActions';
import FailedTracesView from '@/components/FailedTracesView';
import DistributionChart from '@/components/DistributionChart';
import DocumentationContent from '@/components/DocumentationContent';
import ReportView from '@/components/ReportView';
import HomePage from '@/components/HomePage';
import DocumentGenerationPage from '@/components/DocumentGenerationPage';
import Footer from '@/components/Footer';
import { EvaluationSummary, EvaluationResult } from '@/types/cert';
import { colors } from '@/theme/colors';

export default function Home() {
  const [evaluationData, setEvaluationData] = useState<{
    summary: EvaluationSummary;
    results: EvaluationResult[];
  } | null>(null);
  const [activeTab, setActiveTab] = useState('home');

  const handleEvaluationFileLoad = (data: any) => {
    console.log('Loaded data:', data);

    if (!data || typeof data !== 'object') {
      alert('Invalid file: Expected a JSON object');
      return;
    }

    if (!data.summary) {
      alert('Invalid file: Missing "summary" field. Please upload a file generated by cert.evaluation.Evaluator');
      return;
    }

    // Handle different file formats
    let results = data.results;

    // If no results array, try to build from failed_examples and high_scoring_examples
    if (!results || !Array.isArray(results)) {
      const failedExamples = data.failed_examples || [];
      const highScoringExamples = data.high_scoring_examples || [];

      // Convert examples to results format
      results = [
        ...failedExamples.map((ex: any) => ({
          timestamp: ex.timestamp,
          query: ex.input,
          response: ex.output,
          measurement: {
            confidence: ex.score,
            rule: 'evaluation',
            components_used: ['semantic', 'grounding']
          },
          passed: false,
          duration_ms: 0
        })),
        ...highScoringExamples.map((ex: any) => ({
          timestamp: ex.timestamp,
          query: ex.input,
          response: ex.output,
          measurement: {
            confidence: ex.score,
            rule: 'evaluation',
            components_used: ['semantic', 'grounding']
          },
          passed: true,
          duration_ms: 0
        }))
      ];

      // If still no results, use empty array (summary-only mode)
      if (results.length === 0) {
        results = [];
      }
    }

    // Normalize summary field names for different formats
    const normalizedSummary = {
      total_traces: data.summary.total_traces,
      evaluated_traces: data.summary.evaluated_traces || data.summary.total_traces,
      passed_traces: data.summary.passed_traces || data.summary.passed,
      failed_traces: data.summary.failed_traces || data.summary.failed,
      accuracy: data.summary.accuracy || data.summary.pass_rate,
      mean_confidence: data.summary.mean_confidence || data.summary.mean_score,
      threshold_used: data.summary.threshold_used || data.threshold_analysis?.current_threshold || 0.7,
      date_range: data.summary.date_range || {
        start: data.temporal_analysis?.period_start || 'N/A',
        end: data.temporal_analysis?.period_end || 'N/A'
      }
    };

    setEvaluationData({ summary: normalizedSummary, results });
    // Switch to overview tab after loading data
    setActiveTab('overview');
  };

  const handleExportCSV = () => {
    if (!evaluationData) return;

    const { results } = evaluationData;
    const headers = ['Timestamp', 'Query', 'Response', 'Confidence', 'Passed'];
    const rows = results.map(r => [
      r.timestamp,
      `"${r.query.replace(/"/g, '""')}"`,
      `"${(r.response || '').replace(/"/g, '""')}"`,
      r.measurement.confidence.toFixed(3),
      r.passed ? 'Yes' : 'No',
    ]);

    const csv = [headers.join(','), ...rows.map(row => row.join(','))].join('\n');
    const blob = new Blob([csv], { type: 'text/csv' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `evaluation_results_${new Date().toISOString().split('T')[0]}.csv`;
    a.click();
    URL.revokeObjectURL(url);
  };

  const summary = evaluationData?.summary;
  const results = evaluationData?.results || [];
  const isCompliant = summary ? summary.accuracy >= 0.9 : false;

  // Render active tab content
  const renderTabContent = () => {
    switch (activeTab) {
      case 'home':
        return <HomePage />;

      case 'documents':
        return <DocumentGenerationPage />;

      case 'load':
        return (
          <Box maxW="1200px" mx="auto">
            <Box mb="40px" textAlign="center">
              <Text
                fontSize="36px"
                fontWeight="700"
                color={colors.navy}
                mb="12px"
                letterSpacing="-1px"
              >
                Upload Evaluation Results
              </Text>
              <Text fontSize="18px" color={colors.text.secondary} lineHeight="1.6">
                Load your CERT evaluation data to view compliance metrics and analysis
              </Text>
            </Box>

            {/* Privacy Notice */}
            <Card style={{
              borderColor: '#3B82F6',
              background: '#EFF6FF',
              marginBottom: '24px',
              maxWidth: '800px',
              marginLeft: 'auto',
              marginRight: 'auto'
            }}>
              <Grid templateColumns="auto 1fr" gap="16px" alignItems="start">
                <Box
                  w="48px"
                  h="48px"
                  bg="#3B82F6"
                  borderRadius="8px"
                  display="flex"
                  alignItems="center"
                  justifyContent="center"
                  color="white"
                  flexShrink={0}
                >
                  <MdLock size={24} />
                </Box>
                <Box>
                  <Text fontSize="18px" fontWeight="700" color="#1E40AF" mb="12px">
                    Your Data Stays Private
                  </Text>
                  <Text fontSize="15px" color="#1E40AF" lineHeight="1.6" mb="12px">
                    All processing happens locally in your browser. Your uploaded files are never transmitted to our servers or stored anywhere. When you close this tab, your data is permanently deleted from memory.
                  </Text>
                  <Link
                    href="/privacy"
                    fontSize="14px"
                    color="#2563EB"
                    textDecoration="underline"
                    _hover={{ color: '#1D4ED8' }}
                  >
                    Learn more about our privacy practices â†’
                  </Link>
                </Box>
              </Grid>
            </Card>

            <FileUpload
              onFileLoad={handleEvaluationFileLoad}
              accept=".json"
              label="Upload Evaluation Results"
            />

            <Box maxW="800px" mx="auto" mt="32px">
              <Card style={{ borderColor: colors.patience, background: 'white' }}>
                <Text fontSize="18px" fontWeight="700" color={colors.navy} mb="16px">
                  How to generate evaluation results:
                </Text>
                <Code
                  display="block"
                  whiteSpace="pre"
                  p="20px"
                  borderRadius="12px"
                  fontSize="15px"
                  bg={colors.patience}
                  color={colors.navy}
                  lineHeight="1.6"
                  minW="450px"
                >
{`from cert.evaluation import Evaluator

evaluator = Evaluator(threshold=0.7)
results = evaluator.evaluate_log_file(
    log_file="production_traces.jsonl",
    output="evaluation_results.json"
)`}
                </Code>
              </Card>
            </Box>
          </Box>
        );

      case 'overview':
        if (!evaluationData) return null;
        return (
          <>
            <StatusBanner
              isCompliant={isCompliant}
              accuracy={summary!.accuracy}
              failedCount={summary!.failed_traces}
            />

            {/* Metrics Grid */}
            <Grid
              templateColumns={{
                base: '1fr',
                md: 'repeat(2, 1fr)',
                lg: 'repeat(4, 1fr)',
              }}
              gap="20px"
              mb="20px"
            >
              <MetricCard
                label="Accuracy"
                value={`${(summary!.accuracy * 100).toFixed(1)}%`}
                icon={MdAssessment}
                color={summary!.accuracy >= 0.9 ? 'green' : summary!.accuracy >= 0.8 ? 'orange' : 'red'}
                bgColor="rgba(251, 245, 240, 0.8)"
              />
              <MetricCard
                label="Total Traces"
                value={summary!.total_traces.toString()}
                icon={MdList}
                color="blue"
                bgColor="rgba(251, 245, 240, 0.8)"
              />
              <MetricCard
                label="Passed"
                value={summary!.passed_traces.toString()}
                icon={MdCheckCircle}
                color="green"
                bgColor="rgba(251, 245, 240, 0.8)"
              />
              <MetricCard
                label="Failed"
                value={summary!.failed_traces.toString()}
                icon={MdCancel}
                color="red"
                bgColor="rgba(251, 245, 240, 0.8)"
              />
            </Grid>

            <Grid templateColumns={{ base: '1fr', lg: 'repeat(2, 1fr)' }} gap="20px" mb="20px">
              <Card style={{ borderColor: colors.patience, backgroundColor: 'rgba(191, 200, 216, 0.9)' }}>
                <Text fontSize="16px" fontWeight="600" color={colors.text.muted} mb="8px">
                  Mean Confidence
                </Text>
                <Text fontSize="52px" fontWeight="700" color={colors.cobalt} lineHeight="1">
                  {summary!.mean_confidence.toFixed(3)}
                </Text>
                <Text fontSize="15px" color={colors.text.secondary} mt="12px">
                  Threshold: {summary!.threshold_used.toFixed(2)}
                </Text>
                <Text fontSize="15px" color={colors.text.secondary} mt="16px" lineHeight="1.6">
                  Mean confidence of {summary!.mean_confidence.toFixed(3)} suggests {' '}
                  {summary!.mean_confidence > 0.8
                    ? 'strong performance with most predictions highly confident.'
                    : 'moderate performance near the boundary - small improvements will increase compliance.'}
                </Text>
              </Card>

              <Card style={{ borderColor: colors.patience }}>
                <Text fontSize="16px" fontWeight="600" color={colors.text.muted} mb="16px">
                  Evaluation Period
                </Text>
                <Text fontSize="15px" color={colors.text.primary} mb="8px" lineHeight="1.6">
                  <strong>Start:</strong> {summary!.date_range.start}
                </Text>
                <Text fontSize="15px" color={colors.text.primary} mb="12px" lineHeight="1.6">
                  <strong>End:</strong> {summary!.date_range.end}
                </Text>
                <Text fontSize="15px" color={colors.text.secondary} mt="16px" pt="16px" borderTop="1px solid" borderColor={colors.patience}>
                  Total traces evaluated: {summary!.evaluated_traces.toLocaleString()}
                </Text>
              </Card>
            </Grid>

            <QuickActions
              onViewFailed={() => setActiveTab('failed')}
              onViewDistribution={() => setActiveTab('distribution')}
              onExport={handleExportCSV}
            />
          </>
        );

      case 'failed':
        if (!evaluationData) return null;
        return results.length > 0 ? (
          <FailedTracesView results={results} threshold={summary!.threshold_used} />
        ) : (
          <Card style={{ borderColor: colors.patience }}>
            <Text fontSize="18px" fontWeight="700" color={colors.navy} mb="12px">
              No Detailed Trace Data
            </Text>
            <Text fontSize="16px" color={colors.text.secondary} lineHeight="1.6">
              This file contains summary metrics only. {summary!.failed_traces} traces failed based on summary data.
            </Text>
          </Card>
        );

      case 'distribution':
        if (!evaluationData) return null;
        return (
          <Box maxW="900px" mx="auto">
            <Card style={{ borderColor: colors.patience, marginBottom: '24px' }}>
              <Text fontSize="24px" fontWeight="700" color={colors.navy} mb="20px">
                Score Distribution
              </Text>
              {results.length > 0 ? (
                <DistributionChart results={results} threshold={summary!.threshold_used} />
              ) : (
                <Text fontSize="16px" color={colors.text.muted}>
                  No detailed trace data available for distribution analysis.
                </Text>
              )}
            </Card>

            {results.length > 0 && (
              <Card style={{ borderColor: colors.warning, background: '#FEF3C7' }}>
                <Text fontSize="18px" fontWeight="700" color={colors.navy} mb="12px">
                  Critical Finding
                </Text>
                <Text fontSize="16px" color={colors.text.primary} lineHeight="1.7">
                  {(() => {
                    const borderlineCount = results.filter(r =>
                      r.measurement.confidence >= 0.5 && r.measurement.confidence < summary!.threshold_used
                    ).length;
                    const borderlinePercent = ((borderlineCount / results.length) * 100).toFixed(1);

                    return (
                      <>
                        <strong>{borderlineCount} traces ({borderlinePercent}%)</strong> scored between 0.5-{summary!.threshold_used.toFixed(1)} - just below or near the threshold.
                        These represent borderline cases where small improvements could push you to 90%+ compliance.
                        Focus engineering effort here for maximum impact.
                      </>
                    );
                  })()}
                </Text>
              </Card>
            )}
          </Box>
        );

      case 'report':
        if (!evaluationData) return null;
        return <ReportView summary={summary!} results={results} />;

      case 'documentation':
        return (
          <Card style={{ borderColor: colors.patience }}>
            <DocumentationContent />
          </Card>
        );

      default:
        return null;
    }
  };

  return (
    <Box minH="100vh" bg={colors.background} display="flex" flexDirection="column">
      <Navigation
        activeTab={activeTab}
        onTabChange={setActiveTab}
        hasData={!!evaluationData}
      />

      <Box maxW="1600px" mx="auto" px="32px" py="32px" flex="1">
        {renderTabContent()}
      </Box>

      <Footer />
    </Box>
  );
}
