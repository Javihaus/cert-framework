"""
Static compliance content shared between .docx and PDF renderers.

IMPORTANT: This text must match dashboard/content/compliance-text.ts exactly.
Changes here should be mirrored in the TypeScript file.
"""

# Article 15 Definition
ARTICLE15_DEFINITION = """EU AI Act Article 15 requires high-risk AI systems to achieve appropriate levels of accuracy, robustness and cybersecurity, and perform consistently throughout their lifecycle."""

# Regulatory Requirements
ARTICLE15_REQUIREMENTS = """This evaluation addresses requirements under:
• Article 15 (Accuracy, Robustness, Cybersecurity)
• Article 19 (Transparency Obligations for High-Risk AI Systems)"""

# Methodology Overview
METHODOLOGY_OVERVIEW = """CERT Framework uses a dual-component measurement approach validated on Stanford SQuAD v2.0:

1. Semantic Similarity (50%): Detects topic drift and paraphrasing errors using sentence embeddings
2. Term Grounding (50%): Identifies factual hallucinations and numerical errors via NLI analysis

Combined, these components achieve 95.3% accuracy at detecting incorrect outputs (ROC AUC: 0.961)."""

# Evaluation Process
EVALUATION_PROCESS = """Each trace is evaluated by comparing the LLM output against ground truth context. The system generates a confidence score from 0.0 (definitely incorrect) to 1.0 (definitely correct). Traces below the configured threshold are flagged as failures."""

# Compliance Interpretation
COMPLIANCE_INTERPRETATION = """Systems achieving ≥90% accuracy are considered compliant with Article 15 requirements. Scores between 85-90% indicate acceptable performance with monitoring recommended. Scores below 85% require immediate corrective action."""

# Article 15 Detailed Notes
ARTICLE15_DETAILED = """Article 15 (Accuracy & Robustness): This evaluation assesses accuracy across a representative dataset. High-risk systems must achieve and maintain appropriate levels of accuracy throughout their lifecycle. This report provides quantitative evidence of system performance as required for technical documentation."""

# Article 19 Detailed Notes
ARTICLE19_DETAILED = """Article 19 (Transparency): High-risk AI systems must provide sufficient information to enable users to interpret outputs appropriately. This report serves as technical documentation of system performance, evaluation methodology, and compliance status as required by Annex IV, Section 2."""

# Failed Trace Analysis Introduction
FAILED_TRACE_INTRO = """Analysis of failed traces reveals patterns requiring attention. Each failure is documented with confidence scores and categorized by error type to support systematic improvement."""

# Score Distribution Introduction
SCORE_DISTRIBUTION_INTRO = """The confidence score distribution provides insights into system reliability. High-confidence outputs indicate strong alignment with source material, while low-confidence outputs flag potential accuracy issues."""

# Footer Note
FOOTER_NOTE = """This evaluation complies with EU AI Act requirements for technical documentation (Annex IV, Section 2). Generated by CERT Framework."""
